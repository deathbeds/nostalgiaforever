{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Notebook is a Hypothesis\n",
    "\n",
    "1. ~~[If a notebook is hypothesis then it tests something.](informal.ipynb)~~\n",
    "2. __[If a notebook is a hypothesis then it can be tested.](formal.ipynb)__\n",
    "3. ~~[If a notebook is a hypothesis then it will be tested.](continuous.ipynb)~~\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Tests\n",
    "\n",
    "* ### ... promote reproducibility and are reusable.\n",
    "* ### ... transform a hypothesis into an assumption.\n",
    "* ### ... accelerate innovation by avoiding redundancy.\n",
    "* ### ... including narrative improve the ability to share interactive compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    from IPython import get_ipython\n",
    "    from importnb import Notebook, reload\n",
    "    o = __name__ == '__main__'\n",
    "    try: \n",
    "        from .util import __ipython__\n",
    "        from .informal import interactive_computing, notebook_session\n",
    "    except: \n",
    "        %reload_ext pidgin\n",
    "        %pidgin markdown conventions\n",
    "        from util import __ipython__\n",
    "        from informal import interactive_computing, notebook_session\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# [[Python Guide] Testing your code](http://docs.python-guide.org/en/latest/writing/tests/#testing-your-code)\n",
       "\n",
       "* A testing unit should __focus on one tiny bit of functionality and prove it correct__.\n",
       "* Each test unit must be fully independent... \n",
       "* Try hard to make tests that run fast...\n",
       "* Learn your tools and learn how to run a single test or a test case...\n",
       "* Always run the full test suite before a coding session, and run it again after...\n",
       "* It is a good idea to implement a hook that runs all tests before pushing code to a shared repository.\n",
       "* If you are in the middle of a development session and have to interrupt your work, it is a good idea to write a broken unit test about what you want to develop next. When coming back to work, you will have a pointer to where you were and get back on track faster.\n",
       "* ...those bug catching tests are among the most valuable pieces of code in your project.\n",
       "* ~~Use long and descriptive names for testing functions...~~ Write narrative!\n",
       "* ...the testing code will be read as much as or even more than the running code. A unit test whose purpose is unclear is not very helpful in this case.\n",
       "* Another use of the testing code is as an introduction to new ~~developers~~ scientists..."
      ],
      "text/plain": [
       "# [[Python Guide] Testing your code](http://docs.python-guide.org/en/latest/writing/tests/#testing-your-code)\n",
       "\n",
       "* A testing unit should __focus on one tiny bit of functionality and prove it correct__.\n",
       "* Each test unit must be fully independent... \n",
       "* Try hard to make tests that run fast...\n",
       "* Learn your tools and learn how to run a single test or a test case...\n",
       "* Always run the full test suite before a coding session, and run it again after...\n",
       "* It is a good idea to implement a hook that runs all tests before pushing code to a shared repository.\n",
       "* If you are in the middle of a development session and have to interrupt your work, it is a good idea to write a broken unit test about what you want to develop next. When coming back to work, you will have a pointer to where you were and get back on track faster.\n",
       "* ...those bug catching tests are among the most valuable pieces of code in your project.\n",
       "* ~~Use long and descriptive names for testing functions...~~ Write narrative!\n",
       "* ...the testing code will be read as much as or even more than the running code. A unit test whose purpose is unclear is not very helpful in this case.\n",
       "* Another use of the testing code is as an introduction to new ~~developers~~ scientists..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [[Python Guide] Testing your code](http://docs.python-guide.org/en/latest/writing/tests/#testing-your-code)\n",
    "\n",
    "* A testing unit should __focus on one tiny bit of functionality and prove it correct__.\n",
    "* Each test unit must be fully independent... \n",
    "* Try hard to make tests that run fast...\n",
    "* Learn your tools and learn how to run a single test or a test case...\n",
    "* Always run the full test suite before a coding session, and run it again after...\n",
    "* It is a good idea to implement a hook that runs all tests before pushing code to a shared repository.\n",
    "* If you are in the middle of a development session and have to interrupt your work, it is a good idea to write a broken unit test about what you want to develop next. When coming back to work, you will have a pointer to where you were and get back on track faster.\n",
    "* ...those bug catching tests are among the most valuable pieces of code in your project.\n",
    "* ~~Use long and descriptive names for testing functions...~~ Write narrative!\n",
    "* ...the testing code will be read as much as or even more than the running code. A unit test whose purpose is unclear is not very helpful in this case.\n",
    "* Another use of the testing code is as an introduction to new ~~developers~~ scientists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The first test is the hardest to write\n",
       "    \n",
       "    __import__('IPython').display.YouTubeVideo(\"fA7LGqwjhYs\")"
      ],
      "text/plain": [
       "# The first test is the hardest to write\n",
       "    \n",
       "    __import__('IPython').display.YouTubeVideo(\"fA7LGqwjhYs\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/fA7LGqwjhYs\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10f6d2358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first test is the hardest to write\n",
    "    \n",
    "    __import__('IPython').display.YouTubeVideo(\"fA7LGqwjhYs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Built In Python [Doctest](https://docs.python.org/3/library/doctest.html)\n",
       "\n",
       "> Doctests are my first approach to formal notebook testing\n",
       "    \n",
       "    def test_my_string(): \n",
       "        \"\"\">>> assert 'ðŸ’¯'\"\"\"    \n",
       "\n",
       "### Running doctests   \n",
       "\n",
       "Doctests run transparently when `__name__ == '__main__'`.\n",
       "\n",
       "    o  and __import__('doctest').testmod(verbose=2)\n",
       "\n",
       "    \n",
       "* [PEP 257](https://www.python.org/dev/peps/pep-0257/)\n",
       "---"
      ],
      "text/plain": [
       "## Built In Python [Doctest](https://docs.python.org/3/library/doctest.html)\n",
       "\n",
       "> Doctests are my first approach to formal notebook testing\n",
       "    \n",
       "    def test_my_string(): \n",
       "        \"\"\">>> assert 'ðŸ’¯'\"\"\"    \n",
       "\n",
       "### Running doctests   \n",
       "\n",
       "Doctests run transparently when `__name__ == '__main__'`.\n",
       "\n",
       "    o  and __import__('doctest').testmod(verbose=2)\n",
       "\n",
       "    \n",
       "* [PEP 257](https://www.python.org/dev/peps/pep-0257/)\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    assert True\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert True\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert True\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert 'ðŸ’¯'\n",
      "Expecting nothing\n",
      "ok\n",
      "5 items had no tests:\n",
      "    __main__\n",
      "    __main__.InteractiveTest\n",
      "    __main__.InteractiveTest.test_something\n",
      "    __main__.load_tests\n",
      "    __main__.test_hypothesis\n",
      "4 items passed all tests:\n",
      "   1 tests in __main__.__test__.aTest\n",
      "   1 tests in __main__.__test__.interact\n",
      "   1 tests in __main__.test_me\n",
      "   1 tests in __main__.test_my_string\n",
      "4 tests in 9 items.\n",
      "4 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Built In Python [Doctest](https://docs.python.org/3/library/doctest.html)\n",
    "\n",
    "> Doctests are my first approach to formal notebook testing\n",
    "    \n",
    "    def test_my_string(): \n",
    "        \"\"\">>> assert 'ðŸ’¯'\"\"\"    \n",
    "\n",
    "### Running doctests   \n",
    "\n",
    "Doctests run transparently when `__name__ == '__main__'`.\n",
    "\n",
    "    o  and __import__('doctest').testmod(verbose=2)\n",
    "\n",
    "    \n",
    "* [PEP 257](https://www.python.org/dev/peps/pep-0257/)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [Doctest] `__test__` is a reserved [word](https://docs.python.org/3/library/doctest.html#which-docstrings-are-examined) \n",
       "    \n",
       "    __test__ = dict(aTest=\"\"\"This is a docttest\n",
       "    >>> assert True\"\"\")\n",
       "    o  and __import__('doctest').testmod(verbose=2)\n",
       "    \n",
       "> Doctests don't raise exceptions because they are not part of a test suite."
      ],
      "text/plain": [
       "## [Doctest] `__test__` is a reserved [word](https://docs.python.org/3/library/doctest.html#which-docstrings-are-examined) \n",
       "    \n",
       "    __test__ = dict(aTest=\"\"\"This is a docttest\n",
       "    >>> assert True\"\"\")\n",
       "    o  and __import__('doctest').testmod(verbose=2)\n",
       "    \n",
       "> Doctests don't raise exceptions because they are not part of a test suite."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    assert True\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert True\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert 'ðŸ’¯'\n",
      "Expecting nothing\n",
      "ok\n",
      "5 items had no tests:\n",
      "    __main__\n",
      "    __main__.InteractiveTest\n",
      "    __main__.InteractiveTest.test_something\n",
      "    __main__.load_tests\n",
      "    __main__.test_hypothesis\n",
      "3 items passed all tests:\n",
      "   1 tests in __main__.__test__.aTest\n",
      "   1 tests in __main__.test_me\n",
      "   1 tests in __main__.test_my_string\n",
      "3 tests in 8 items.\n",
      "3 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [Doctest] `__test__` is a reserved [word](https://docs.python.org/3/library/doctest.html#which-docstrings-are-examined) \n",
    "    \n",
    "    __test__ = dict(aTest=\"\"\"This is a docttest\n",
    "    >>> assert True\"\"\")\n",
    "    o  and __import__('doctest').testmod(verbose=2)\n",
    "    \n",
    "> Doctests don't raise exceptions because they are not part of a test suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Lifecycle of a Notebook Session\n",
       "\n",
       "A notebook session is semi-permanant.\n",
       "\n",
       "---\n",
       "\n",
       "1. ### $t_{0}$ - *setUp* and __init__ialize the Notebook \n",
       "\n",
       "    ~~Hope~~ Assume that your environment is set up.\n",
       "\n",
       "2. ### $t_i$   - repeatedly __enter__ and __exit__ the _interactive computing_ session\n",
       "\n",
       "    Lose your mind.\n",
       "\n",
       "3. ### $t_{final}$ - tearDown the notebook session.\n",
       "\n",
       "    Lose your memory.\n",
       "\n",
       "4. # ðŸ˜µðŸ˜µðŸ˜µðŸ˜µ"
      ],
      "text/plain": [
       "# Lifecycle of a Notebook Session\n",
       "\n",
       "A notebook session is semi-permanant.\n",
       "\n",
       "---\n",
       "\n",
       "1. ### $t_{0}$ - *setUp* and __init__ialize the Notebook \n",
       "\n",
       "    ~~Hope~~ Assume that your environment is set up.\n",
       "\n",
       "2. ### $t_i$   - repeatedly __enter__ and __exit__ the _interactive computing_ session\n",
       "\n",
       "    Lose your mind.\n",
       "\n",
       "3. ### $t_{final}$ - tearDown the notebook session.\n",
       "\n",
       "    Lose your memory.\n",
       "\n",
       "4. # ðŸ˜µðŸ˜µðŸ˜µðŸ˜µ"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    notebook_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    https://en.wikipedia.org/wiki/XUnit\n",
       "\n",
       "# [Anatomy of a unit test](https://en.wikipedia.org/wiki/XUnit)\n",
       "    \n",
       "* Test Runner\n",
       "* Test Case\n",
       "* Test Fixtures\n",
       "* Test Suite\n",
       "* Test Results\n",
       "* Assertions\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "    https://en.wikipedia.org/wiki/XUnit\n",
       "\n",
       "# [Anatomy of a unit test](https://en.wikipedia.org/wiki/XUnit)\n",
       "    \n",
       "* Test Runner\n",
       "* Test Case\n",
       "* Test Fixtures\n",
       "* Test Suite\n",
       "* Test Results\n",
       "* Assertions\n",
       "\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://en.m.wikipedia.org/wiki/XUnit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10fb28470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    https://en.wikipedia.org/wiki/XUnit\n",
    "\n",
    "# [Anatomy of a unit test](https://en.wikipedia.org/wiki/XUnit)\n",
    "    \n",
    "* Test Runner\n",
    "* Test Case\n",
    "* Test Fixtures\n",
    "* Test Suite\n",
    "* Test Results\n",
    "* Assertions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Python has Unit Testing\n",
       "\n",
       "    from unittest import TestCase, main\n",
       "    \n",
       "\n",
       "Using `unittest` in `IPython` allows the author to take advantage of `ÃŒPython` magics commands for dense tests.\n",
       "\n",
       "\n",
       "## Unit testing may be using interactively.    \n",
       "    \n",
       "    import unittest\n",
       "    \n",
       "    class InteractiveTest(unittest.TestCase):\n",
       "        def test_something(test):\n",
       "            assert test\n",
       "            \n",
       "    try:   o and unittest.main(argv='discover --verbose'.split())\n",
       "    except SystemExit: ..."
      ],
      "text/plain": [
       "# Python has Unit Testing\n",
       "\n",
       "    from unittest import TestCase, main\n",
       "    \n",
       "\n",
       "Using `unittest` in `IPython` allows the author to take advantage of `ÃŒPython` magics commands for dense tests.\n",
       "\n",
       "\n",
       "## Unit testing may be using interactively.    \n",
       "    \n",
       "    import unittest\n",
       "    \n",
       "    class InteractiveTest(unittest.TestCase):\n",
       "        def test_something(test):\n",
       "            assert test\n",
       "            \n",
       "    try:   o and unittest.main(argv='discover --verbose'.split())\n",
       "    except SystemExit: ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_something (__main__.InteractiveTest) ... ok\n",
      "aTest (__main__.__test__)\n",
      "Doctest: __main__.__test__.aTest ... ok\n",
      "test_me (__main__)\n",
      "Doctest: __main__.test_me ... ok\n",
      "test_my_string (__main__)\n",
      "Doctest: __main__.test_my_string ... ok\n",
      "unittest.case.FunctionTestCase (test_me)\n",
      ">>> assert True ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Python has Unit Testing\n",
    "\n",
    "    from unittest import TestCase, main\n",
    "    \n",
    "\n",
    "Using `unittest` in `IPython` allows the author to take advantage of `ÃŒPython` magics commands for dense tests.\n",
    "\n",
    "\n",
    "## Unit testing may be using interactively.    \n",
    "    \n",
    "    import unittest\n",
    "    \n",
    "    class InteractiveTest(unittest.TestCase):\n",
    "        def test_something(test):\n",
    "            assert test\n",
    "            \n",
    "    try:   o and unittest.main(argv='discover --verbose'.split())\n",
    "    except SystemExit: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [Unittest] + [Doctest]\n",
       "\n",
       "    def test_me(): \n",
       "        \"\"\">>> assert True\"\"\"\n",
       "        assert True\n",
       "\n",
       "    def load_tests(loader, tests, ignore):\n",
       "        import doctest\n",
       "        tests.addTests(doctest.DocTestSuite(__import__(__name__)))\n",
       "        tests.addTest(unittest.FunctionTestCase(test_me))\n",
       "        return tests\n",
       "\n",
       "    try:   o and unittest.main(argv='formal.ipynb --verbose'.split())\n",
       "    except SystemExit: ...\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "## [Unittest] + [Doctest]\n",
       "\n",
       "    def test_me(): \n",
       "        \"\"\">>> assert True\"\"\"\n",
       "        assert True\n",
       "\n",
       "    def load_tests(loader, tests, ignore):\n",
       "        import doctest\n",
       "        tests.addTests(doctest.DocTestSuite(__import__(__name__)))\n",
       "        tests.addTest(unittest.FunctionTestCase(test_me))\n",
       "        return tests\n",
       "\n",
       "    try:   o and unittest.main(argv='formal.ipynb --verbose'.split())\n",
       "    except SystemExit: ...\n",
       "\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_something (__main__.InteractiveTest) ... ok\n",
      "aTest (__main__.__test__)\n",
      "Doctest: __main__.__test__.aTest ... ok\n",
      "test_me (__main__)\n",
      "Doctest: __main__.test_me ... ok\n",
      "test_my_string (__main__)\n",
      "Doctest: __main__.test_my_string ... ok\n",
      "unittest.case.FunctionTestCase (test_me)\n",
      ">>> assert True ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "## [Unittest] + [Doctest]\n",
    "\n",
    "    def test_me(): \n",
    "        \"\"\">>> assert True\"\"\"\n",
    "        assert True\n",
    "\n",
    "    def load_tests(loader, tests, ignore):\n",
    "        import doctest\n",
    "        tests.addTests(doctest.DocTestSuite(__import__(__name__)))\n",
    "        tests.addTest(unittest.FunctionTestCase(test_me))\n",
    "        return tests\n",
    "\n",
    "    try:   o and unittest.main(argv='formal.ipynb --verbose'.split())\n",
    "    except SystemExit: ...\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Testing the module\n",
       "\n",
       "We may import our notebooks...\n",
       "    \n",
       "    with Notebook():\n",
       "        try: import formal\n",
       "        except: from . import formal\n",
       "        reload(formal)\n",
       "    \n",
       "    __test__['interact'] = \"\"\">>> assert True\"\"\"\n",
       "    \n",
       "... and test them as a module.\n",
       "\n",
       "    try:   o and unittest.main(formal, argv='discover --verbose'.split())\n",
       "    except SystemExit: ...\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "## Testing the module\n",
       "\n",
       "We may import our notebooks...\n",
       "    \n",
       "    with Notebook():\n",
       "        try: import formal\n",
       "        except: from . import formal\n",
       "        reload(formal)\n",
       "    \n",
       "    __test__['interact'] = \"\"\">>> assert True\"\"\"\n",
       "    \n",
       "... and test them as a module.\n",
       "\n",
       "    try:   o and unittest.main(formal, argv='discover --verbose'.split())\n",
       "    except SystemExit: ...\n",
       "\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_something (formal.InteractiveTest) ... ok\n",
      "aTest (formal.__test__)\n",
      "Doctest: formal.__test__.aTest ... ok\n",
      "interact (formal.__test__)\n",
      "Doctest: formal.__test__.interact ... ok\n",
      "test_me (formal)\n",
      "Doctest: formal.test_me ... ok\n",
      "test_my_string (formal)\n",
      "Doctest: formal.test_my_string ... ok\n",
      "unittest.case.FunctionTestCase (test_me)\n",
      ">>> assert True ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "## Testing the module\n",
    "\n",
    "We may import our notebooks...\n",
    "    \n",
    "    with Notebook():\n",
    "        try: import formal\n",
    "        except: from . import formal\n",
    "        reload(formal)\n",
    "    \n",
    "    __test__['interact'] = \"\"\">>> assert True\"\"\"\n",
    "    \n",
    "... and test them as a module.\n",
    "\n",
    "    try:   o and unittest.main(formal, argv='discover --verbose'.split())\n",
    "    except SystemExit: ...\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The Hypothesis Project\n",
       "\n",
       "    https://hypothesis.readthedocs.io/en/master/index.html"
      ],
      "text/plain": [
       "# The Hypothesis Project\n",
       "\n",
       "    https://hypothesis.readthedocs.io/en/master/index.html"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://hypothesis.readthedocs.io/en/master/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10f782ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The Hypothesis Project\n",
    "\n",
    "    https://hypothesis.readthedocs.io/en/master/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hypothesis has the prettiest API in all of Python.\n",
       "    \n",
       "    from hypothesis import assume, given, settings, infer, HealthCheck\n",
       "    \n",
       "    @settings(suppress_health_check=[HealthCheck.return_value])\n",
       "    @given(a=infer)\n",
       "    def test_hypothesis(a: str): \n",
       "        # print(a)\n",
       "        return a\n",
       "        \n",
       "    o and test_hypothesis()"
      ],
      "text/plain": [
       "# Hypothesis has the prettiest API in all of Python.\n",
       "    \n",
       "    from hypothesis import assume, given, settings, infer, HealthCheck\n",
       "    \n",
       "    @settings(suppress_health_check=[HealthCheck.return_value])\n",
       "    @given(a=infer)\n",
       "    def test_hypothesis(a: str): \n",
       "        # print(a)\n",
       "        return a\n",
       "        \n",
       "    o and test_hypothesis()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hypothesis has the prettiest API in all of Python.\n",
    "    \n",
    "    from hypothesis import assume, given, settings, infer, HealthCheck\n",
    "    \n",
    "    @settings(suppress_health_check=[HealthCheck.return_value])\n",
    "    @given(a=infer)\n",
    "    def test_hypothesis(a: str): \n",
    "        # print(a)\n",
    "        return a\n",
    "        \n",
    "    o and test_hypothesis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­\n",
       "\n",
       "Unit test doesn't find the hypothesis test \n",
       "    \n",
       "    try:   o and unittest.main(formal, argv='discover --verbose'.split())\n",
       "    except SystemExit: ..."
      ],
      "text/plain": [
       "# ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­\n",
       "\n",
       "Unit test doesn't find the hypothesis test \n",
       "    \n",
       "    try:   o and unittest.main(formal, argv='discover --verbose'.split())\n",
       "    except SystemExit: ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_something (formal.InteractiveTest) ... ok\n",
      "aTest (formal.__test__)\n",
      "Doctest: formal.__test__.aTest ... ok\n",
      "interact (formal.__test__)\n",
      "Doctest: formal.__test__.interact ... ok\n",
      "test_me (formal)\n",
      "Doctest: formal.test_me ... ok\n",
      "test_my_string (formal)\n",
      "Doctest: formal.test_my_string ... ok\n",
      "unittest.case.FunctionTestCase (test_me)\n",
      ">>> assert True ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.014s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­\n",
    "\n",
    "Unit test doesn't find the hypothesis test \n",
    "    \n",
    "    try:   o and unittest.main(formal, argv='discover --verbose'.split())\n",
    "    except SystemExit: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary\n",
       "\n",
       "---\n",
       "\n",
       "* ### A notebook may test many units.\n",
       "* ### Test suites manage the complexities of test discovery, execution, and reporting.\n",
       "* ### Using built in testing methods mature notebooks to formal tests."
      ],
      "text/plain": [
       "# Summary\n",
       "\n",
       "---\n",
       "\n",
       "* ### A notebook may test many units.\n",
       "* ### Test suites manage the complexities of test discovery, execution, and reporting.\n",
       "* ### Using built in testing methods mature notebooks to formal tests."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "\n",
    "---\n",
    "\n",
    "* ### A notebook may test many units.\n",
    "* ### Test suites manage the complexities of test discovery, execution, and reporting.\n",
    "* ### Using built in testing methods mature notebooks to formal tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. ~~[If a notebook is hypothesis then it tests something.](informal.ipynb)~~\n",
       "2. __[If a notebook is a hypothesis then it can be tested.](formal.ipynb)__\n",
       "3. ~~[If a notebook is a hypothesis then it will be tested.](continuous.ipynb)~~"
      ],
      "text/plain": [
       "1. ~~[If a notebook is hypothesis then it tests something.](informal.ipynb)~~\n",
       "2. __[If a notebook is a hypothesis then it can be tested.](formal.ipynb)__\n",
       "3. ~~[If a notebook is a hypothesis then it will be tested.](continuous.ipynb)~~"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1. ~~[If a notebook is hypothesis then it tests something.](informal.ipynb)~~\n",
    "2. __[If a notebook is a hypothesis then it can be tested.](formal.ipynb)__\n",
    "3. ~~[If a notebook is a hypothesis then it will be tested.](continuous.ipynb)~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
