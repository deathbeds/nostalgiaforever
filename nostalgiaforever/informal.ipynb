{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook is a hypothesis\n",
    "\n",
    "1. __[If a notebook is hypothesis then it tests something.](informal.ipynb)__\n",
    "2. ~~[If a notebook is a hypothesis then it can be tested.](formal.ipynb)~~\n",
    "3. ~~[If a notebook is a hypothesis then it will be tested.](continuous.ipynb)~~\n",
    "\n",
    "\n",
    "[![Data Driven Journalism](https://camo.githubusercontent.com/a8d4be63da2f73339f35839d4c006f080b13104a/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f342f34382f446174615f64726976656e5f6a6f75726e616c69736d5f70726f636573732e6a7067)]()\n",
    "\n",
    "> ### Science is rapidly becoming more relevent in popular culture & [modern notebooks are having an impact](https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    __file__ = globals().get('__file__', 'informal.ipynb')\n",
    "    from IPython import get_ipython\n",
    "    try: \n",
    "        from .util import __ipython__\n",
    "    except: \n",
    "        if __name__ == '__main__':\n",
    "            %reload_ext pidgin\n",
    "            %pidgin conventions markdown \n",
    "\n",
    "        from nostalgiaforever.util import __ipython__\n",
    "        \n",
    "    from graphviz import Source\n",
    "    interactive_computing = Source(\"\"\"digraph {rankdir=\"LR\" layout=\"fdp\" \n",
    "             subgraph cluster_ic { label=\"Interactive Computing\" subgraph cluster_human {label=\"human\" read -> write}\n",
    "                 subgraph cluster_machine {label=\"machine\" eval -> print}\n",
    "                 write -> eval; print -> read}}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __[If a notebook is a hypothesis then it tests something.](nostalgiaforever/informal.ipynb)__\n",
    "\n",
    "* ### If something is a hypothesis then it can by tested.\n",
    "\n",
    "* ### The first test is the hardest to write.\n",
    "\n",
    "* ### An interactive computing session experimenting with code or data is a test.\n",
    "    \n",
    "* ### _Informal_ testing does not explicitly test for errors while _formal_ testing does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Lifecycle of a Notebook Session\n",
       "\n",
       "A notebook session is semi-permanant.\n",
       "\n",
       "---\n",
       "\n",
       "1. ### $t_{0}$ - *setUp* and __init__ialize the Notebook \n",
       "\n",
       "    ~~Hope~~ Assume that your environment is set up.\n",
       "\n",
       "2. ### $t_i$   - repeatedly __enter__ and __exit__ the _interactive computing_ session\n",
       "\n",
       "    Lose your mind.\n",
       "\n",
       "3. ### $t_{final}$ - tearDown the notebook session.\n",
       "\n",
       "    Lose your memory.\n",
       "\n",
       "4. # ðŸ˜µðŸ˜µðŸ˜µðŸ˜µ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    from IPython.display import Markdown\n",
    "    notebook_session = Markdown(\"\"\"# Lifecycle of a Notebook Session\n",
    "\n",
    "    A notebook session is semi-permanant.\n",
    "\n",
    "    ---\n",
    "\n",
    "    1. ### $t_{0}$ - *setUp* and __init__ialize the Notebook \n",
    "\n",
    "        ~~Hope~~ Assume that your environment is set up.\n",
    "\n",
    "    2. ### $t_i$   - repeatedly __enter__ and __exit__ the _interactive computing_ session\n",
    "    \n",
    "        Lose your mind.\n",
    "\n",
    "    3. ### $t_{final}$ - tearDown the notebook session.\n",
    "    \n",
    "        Lose your memory.\n",
    "\n",
    "    4. # ðŸ˜µðŸ˜µðŸ˜µðŸ˜µ\"\"\"); notebook_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<hr/><hr/><hr/><hr/><hr/>\n",
       "\n",
       "# Interactive Computing\n",
       "\n",
       "> ## Sometimes I think the only universal in the computing field is the fetch-execute cycle.\n",
       ">> [Alan Perlis](http://www.cs.yale.edu/homes/perlis-alan/quotes.html)\n",
       "\n",
       "---\n",
       "\n",
       "    interactive_computing # is a conversation between a human and machines."
      ],
      "text/plain": [
       "<hr/><hr/><hr/><hr/><hr/>\n",
       "\n",
       "# Interactive Computing\n",
       "\n",
       "> ## Sometimes I think the only universal in the computing field is the fetch-execute cycle.\n",
       ">> [Alan Perlis](http://www.cs.yale.edu/homes/perlis-alan/quotes.html)\n",
       "\n",
       "---\n",
       "\n",
       "    interactive_computing # is a conversation between a human and machines."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"225pt\" height=\"185pt\"\n",
       " viewBox=\"0.00 0.00 225.00 185.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 181)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-181 221,-181 221,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\"><title>cluster_ic</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"-0.261883,-0.140888 -0.261883,-177.141 216.738,-177.141 216.738,-0.140888 -0.261883,-0.140888\"/>\n",
       "<text text-anchor=\"middle\" x=\"108.238\" y=\"-161.941\" font-family=\"Times,serif\" font-size=\"14.00\">Interactive Computing</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\"><title>cluster_human</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7.84858,-24.0821 7.84858,-147.082 102.849,-147.082 102.849,-24.0821 7.84858,-24.0821\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.3486\" y=\"-131.882\" font-family=\"Times,serif\" font-size=\"14.00\">human</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\"><title>cluster_machine</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"115.896,-8.08859 115.896,-131.089 208.896,-131.089 208.896,-8.08859 115.896,-8.08859\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.396\" y=\"-115.889\" font-family=\"Times,serif\" font-size=\"14.00\">machine</text>\n",
       "</g>\n",
       "<!-- read -->\n",
       "<g id=\"node1\" class=\"node\"><title>read</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"47.8785\" cy=\"-99.1761\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.8785\" y=\"-94.9761\" font-family=\"Times,serif\" font-size=\"14.00\">read</text>\n",
       "</g>\n",
       "<!-- write -->\n",
       "<g id=\"node2\" class=\"node\"><title>write</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"44.55\" cy=\"-49.6309\" rx=\"28.0565\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"44.55\" y=\"-45.4309\" font-family=\"Times,serif\" font-size=\"14.00\">write</text>\n",
       "</g>\n",
       "<!-- read&#45;&gt;write -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>read&#45;&gt;write</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M46.658,-81.0086C46.5947,-80.0662 46.5304,-79.11 46.4657,-78.146\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"49.9329,-77.539 45.7704,-67.7962 42.9486,-78.0083 49.9329,-77.539\"/>\n",
       "</g>\n",
       "<!-- eval -->\n",
       "<g id=\"node3\" class=\"node\"><title>eval</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170.866\" cy=\"-33.9945\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.866\" y=\"-29.7945\" font-family=\"Times,serif\" font-size=\"14.00\">eval</text>\n",
       "</g>\n",
       "<!-- write&#45;&gt;eval -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>write&#45;&gt;eval</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.5837,-46.1607C90.6971,-43.9184 114.462,-40.9766 134.086,-38.5475\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.714,-41.9965 144.208,-37.2945 133.854,-35.0496 134.714,-41.9965\"/>\n",
       "</g>\n",
       "<!-- print -->\n",
       "<g id=\"node4\" class=\"node\"><title>print</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.195\" cy=\"-83.5398\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.195\" y=\"-79.3398\" font-family=\"Times,serif\" font-size=\"14.00\">print</text>\n",
       "</g>\n",
       "<!-- eval&#45;&gt;print -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>eval&#45;&gt;print</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.087,-52.162C172.15,-53.1045 172.214,-54.0607 172.279,-55.0246\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.812,-55.6316 172.974,-65.3745 175.796,-55.1624 168.812,-55.6316\"/>\n",
       "</g>\n",
       "<!-- print&#45;&gt;read -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>print&#45;&gt;read</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M147.406,-86.8559C129.152,-89.1155 104.749,-92.1363 84.6753,-94.6212\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.1226,-91.1628 74.6283,-95.8649 84.9826,-98.1098 84.1226,-91.1628\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x113600588>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "<hr/><hr/><hr/><hr/><hr/>\n",
    "\n",
    "# Interactive Computing\n",
    "\n",
    "> ## Sometimes I think the only universal in the computing field is the fetch-execute cycle.\n",
    ">> [Alan Perlis](http://www.cs.yale.edu/homes/perlis-alan/quotes.html)\n",
    "\n",
    "---\n",
    "\n",
    "    interactive_computing # is a conversation between a human and machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Literate Programming\n",
       "\n",
       "> ## Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.\n",
       "> ### ... surely nobody wants to admit writing an illiterate program.\n",
       "\n",
       ">> [Donald Knuth]({{computing.people['knuth']}}) - [Literate Programming](http://roxygen.org/knuth-literate-programming.pdf)"
      ],
      "text/plain": [
       "# Literate Programming\n",
       "\n",
       "> ## Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.\n",
       "> ### ... surely nobody wants to admit writing an illiterate program.\n",
       "\n",
       ">> [Donald Knuth]({{computing.people['knuth']}}) - [Literate Programming](http://roxygen.org/knuth-literate-programming.pdf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Literate Programming\n",
    "\n",
    "> ## Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.\n",
    "> ### ... surely nobody wants to admit writing an illiterate program.\n",
    "\n",
    ">> [Donald Knuth]({{computing.people['knuth']}}) - [Literate Programming](http://roxygen.org/knuth-literate-programming.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# $Literate Computing = \\int_{t_0}^{t_f}{\\dot{Literate Programming(t)}{Interactive Computing}(t-Ï„)}{dÏ„}$\n",
       "\n",
       "  "
      ],
      "text/plain": [
       "# $Literate Computing = \\int_{t_0}^{t_f}{\\dot{Literate Programming(t)}{Interactive Computing}(t-Ï„)}{dÏ„}$\n",
       "\n",
       "  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# $Literate Computing = \\int_{t_0}^{t_f}{\\dot{Literate Programming(t)}{Interactive Computing}(t-Ï„)}{dÏ„}$\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Data & Compute are modern scientific research equipment\n",
       "\n",
       "    graph {rankdir=\"LR\"; data--science--computing--data}"
      ],
      "text/plain": [
       "## Data & Compute are modern scientific research equipment\n",
       "\n",
       "    graph {rankdir=\"LR\"; data--science--computing--data}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"302pt\" height=\"67pt\"\n",
       " viewBox=\"0.00 0.00 302.12 67.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 63)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-63 298.122,-63 298.122,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- science -->\n",
       "<g id=\"node2\" class=\"node\"><title>science</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"126.128\" cy=\"-41\" rx=\"36.2558\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.128\" y=\"-36.8\" font-family=\"Times,serif\" font-size=\"14.00\">science</text>\n",
       "</g>\n",
       "<!-- data&#45;&#45;science -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>data&#45;&#45;science</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.7607,-23.8634C65.0132,-26.7648 79.9513,-30.3022 93.0668,-33.4079\"/>\n",
       "</g>\n",
       "<!-- computing -->\n",
       "<g id=\"node3\" class=\"node\"><title>computing</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"246.189\" cy=\"-18\" rx=\"47.8668\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"246.189\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">computing</text>\n",
       "</g>\n",
       "<!-- science&#45;&#45;computing -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>science&#45;&#45;computing</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.014,-34.5932C173.387,-31.988 189.003,-28.9457 203.186,-26.1828\"/>\n",
       "</g>\n",
       "<!-- computing&#45;&#45;data -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>computing&#45;&#45;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.708,-15.363C186.828,-14.7976 174.072,-14.2848 162.255,-14 130.151,-13.2262 122.097,-12.9657 90,-14 78.1413,-14.3821 65.0265,-15.1744 53.9246,-15.9538\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1136de8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Data & Compute are modern scientific research equipment\n",
    "\n",
    "    graph {rankdir=\"LR\"; data--science--computing--data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# [\"Literate computing\" and computational reproducibility: IPython in the age of data-driven journalism](http://blog.fperez.org/2013/04/literate-computing-and-computational.html)\n",
       "\n",
       "> Our job with Jupyter~~IPython~~ is to think deeply about questions regarding the intersection of _**computing, data and science**_, but it's clear to me at this point that we can contribute in contexts beyond pure scientific research. I hope we'll be able to provide folks who have a _**direct intersection with the public**_, such as journalists, with tools that help a more informed and productive debate.\n",
       ">> - [Fernando Perez](http://blog.fperez.org)"
      ],
      "text/plain": [
       "# [\"Literate computing\" and computational reproducibility: IPython in the age of data-driven journalism](http://blog.fperez.org/2013/04/literate-computing-and-computational.html)\n",
       "\n",
       "> Our job with Jupyter~~IPython~~ is to think deeply about questions regarding the intersection of _**computing, data and science**_, but it's clear to me at this point that we can contribute in contexts beyond pure scientific research. I hope we'll be able to provide folks who have a _**direct intersection with the public**_, such as journalists, with tools that help a more informed and productive debate.\n",
       ">> - [Fernando Perez](http://blog.fperez.org)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [\"Literate computing\" and computational reproducibility: IPython in the age of data-driven journalism](http://blog.fperez.org/2013/04/literate-computing-and-computational.html)\n",
    "\n",
    "> Our job with Jupyter~~IPython~~ is to think deeply about questions regarding the intersection of _**computing, data and science**_, but it's clear to me at this point that we can contribute in contexts beyond pure scientific research. I hope we'll be able to provide folks who have a _**direct intersection with the public**_, such as journalists, with tools that help a more informed and productive debate.\n",
    ">> - [Fernando Perez](http://blog.fperez.org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The scientist is a context manager\n",
       "\n",
       "A scientist internalizes knowledge while executing their experimental designs to test a hypothesis.\n",
       "    \n",
       "    from contextlib import contextmanager\n",
       "    @contextmanager\n",
       "    def theScientist(*independent_arguments, response=None, who: ['Human', 'Machine'] = 'Human', **experiment_settings):\n",
       "        ...\n",
       "        f\"\"\"Setup the experiment with {independent_arguments} and {experiment_settings}\"\"\"\n",
       "        ...\n",
       "        yield response\n",
       "        ...\n",
       "        f\"\"\"Clean up and communicate your results to {who}.\"\"\"\n",
       "        \n",
       "---\n",
       "        \n",
       "    with theScientist() as experiment:\n",
       "        ..."
      ],
      "text/plain": [
       "# The scientist is a context manager\n",
       "\n",
       "A scientist internalizes knowledge while executing their experimental designs to test a hypothesis.\n",
       "    \n",
       "    from contextlib import contextmanager\n",
       "    @contextmanager\n",
       "    def theScientist(*independent_arguments, response=None, who: ['Human', 'Machine'] = 'Human', **experiment_settings):\n",
       "        ...\n",
       "        f\"\"\"Setup the experiment with {independent_arguments} and {experiment_settings}\"\"\"\n",
       "        ...\n",
       "        yield response\n",
       "        ...\n",
       "        f\"\"\"Clean up and communicate your results to {who}.\"\"\"\n",
       "        \n",
       "---\n",
       "        \n",
       "    with theScientist() as experiment:\n",
       "        ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The scientist is a context manager\n",
    "\n",
    "A scientist internalizes knowledge while executing their experimental designs to test a hypothesis.\n",
    "    \n",
    "    from contextlib import contextmanager\n",
    "    @contextmanager\n",
    "    def theScientist(*independent_arguments, response=None, who: ['Human', 'Machine'] = 'Human', **experiment_settings):\n",
    "        ...\n",
    "        f\"\"\"Setup the experiment with {independent_arguments} and {experiment_settings}\"\"\"\n",
    "        ...\n",
    "        yield response\n",
    "        ...\n",
    "        f\"\"\"Clean up and communicate your results to {who}.\"\"\"\n",
    "        \n",
    "---\n",
    "        \n",
    "    with theScientist() as experiment:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "---\n",
       "---\n",
       "\n",
       "# Statistical hypothesis testing allows computers to test hypotheses.\n",
       "\n",
       "---\n",
       "# Design of experiments allows people to test hypotheses.\n",
       "\n",
       "---\n",
       "---\n",
       "---"
      ],
      "text/plain": [
       "---\n",
       "---\n",
       "---\n",
       "\n",
       "# Statistical hypothesis testing allows computers to test hypotheses.\n",
       "\n",
       "---\n",
       "# Design of experiments allows people to test hypotheses.\n",
       "\n",
       "---\n",
       "---\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# Statistical hypothesis testing allows computers to test hypotheses.\n",
    "\n",
    "---\n",
    "# Design of experiments allows people to test hypotheses.\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [On Style] There are style guides for programming.\n",
       "\n",
       "* [Zen of Python](https://www.python.org/dev/peps/pep-0020/)\n",
       "* [Zen of Numpy](http://technicaldiscovery.blogspot.com/2010/11/zen-of-numpy.html)\n",
       "* [Zen of SymPy](https://www.google.com/search?q=zen+of+sympy&oq=zen+of+sympy&aqs=chrome..69i57.1863j0j7&sourceid=chrome&ie=UTF-8)\n",
       "* ~~Zen of Notebooks~~"
      ],
      "text/plain": [
       "## [On Style] There are style guides for programming.\n",
       "\n",
       "* [Zen of Python](https://www.python.org/dev/peps/pep-0020/)\n",
       "* [Zen of Numpy](http://technicaldiscovery.blogspot.com/2010/11/zen-of-numpy.html)\n",
       "* [Zen of SymPy](https://www.google.com/search?q=zen+of+sympy&oq=zen+of+sympy&aqs=chrome..69i57.1863j0j7&sourceid=chrome&ie=UTF-8)\n",
       "* ~~Zen of Notebooks~~"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## [On Style] There are style guides for programming.\n",
    "\n",
    "* [Zen of Python](https://www.python.org/dev/peps/pep-0020/)\n",
    "* [Zen of Numpy](http://technicaldiscovery.blogspot.com/2010/11/zen-of-numpy.html)\n",
    "* [Zen of SymPy](https://www.google.com/search?q=zen+of+sympy&oq=zen+of+sympy&aqs=chrome..69i57.1863j0j7&sourceid=chrome&ie=UTF-8)\n",
    "* ~~Zen of Notebooks~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [On Style] Style guides for the notebook.\n",
       "\n",
       "> ## What we learned about teaching with notebooks (in Oriole)\n",
       ">> [Paco Nathan - Oriole: a new learning medium based on Jupyter + Docker](http://nbviewer.jupyter.org/github/jupyterday-atlanta-2016/oriole_jupyterday_atl/blob/master/oriole_talk.ipynb#What-we-learned-about-teaching-with-notebooks)"
      ],
      "text/plain": [
       "## [On Style] Style guides for the notebook.\n",
       "\n",
       "> ## What we learned about teaching with notebooks (in Oriole)\n",
       ">> [Paco Nathan - Oriole: a new learning medium based on Jupyter + Docker](http://nbviewer.jupyter.org/github/jupyterday-atlanta-2016/oriole_jupyterday_atl/blob/master/oriole_talk.ipynb#What-we-learned-about-teaching-with-notebooks)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## [On Style] Style guides for the notebook.\n",
    "\n",
    "> ## What we learned about teaching with notebooks (in Oriole)\n",
    ">> [Paco Nathan - Oriole: a new learning medium based on Jupyter + Docker](http://nbviewer.jupyter.org/github/jupyterday-atlanta-2016/oriole_jupyterday_atl/blob/master/oriole_talk.ipynb#What-we-learned-about-teaching-with-notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "* ## focus on a concise \"unit of thought\"\n",
       "* invest the time and editorial effort to create a good introduction\n",
       "* keep your narrative simple and reasonably linear\n",
       "* \"chunk\" both the text and the code into understandable parts\n",
       "* alternate between text, code, output, further links, etc.\n",
       "* leverage markdown by providing interesting links for background, deep-dive, etc.\n",
       "* code cells should not be long, < 10 lines\n",
       "* code cells must show that they've run, producing at least *some* output \n",
       "* load data from the container, not the network\n",
       "* ## clear all output then \"Run All\" -- or it didn't happen\n",
       "* video narratives: there's text, and there's subtext...\n",
       "* pause after each \"beat\" -- smile, breathe, allow people to follow you\n"
      ],
      "text/plain": [
       "* ## focus on a concise \"unit of thought\"\n",
       "* invest the time and editorial effort to create a good introduction\n",
       "* keep your narrative simple and reasonably linear\n",
       "* \"chunk\" both the text and the code into understandable parts\n",
       "* alternate between text, code, output, further links, etc.\n",
       "* leverage markdown by providing interesting links for background, deep-dive, etc.\n",
       "* code cells should not be long, < 10 lines\n",
       "* code cells must show that they've run, producing at least *some* output \n",
       "* load data from the container, not the network\n",
       "* ## clear all output then \"Run All\" -- or it didn't happen\n",
       "* video narratives: there's text, and there's subtext...\n",
       "* pause after each \"beat\" -- smile, breathe, allow people to follow you"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    nb_style = Markdown(\"\"\"* ## focus on a concise \"unit of thought\"\n",
    "    * invest the time and editorial effort to create a good introduction\n",
    "    * keep your narrative simple and reasonably linear\n",
    "    * \"chunk\" both the text and the code into understandable parts\n",
    "    * alternate between text, code, output, further links, etc.\n",
    "    * leverage markdown by providing interesting links for background, deep-dive, etc.\n",
    "    * code cells should not be long, < 10 lines\n",
    "    * code cells must show that they've run, producing at least *some* output \n",
    "    * load data from the container, not the network\n",
    "    * ## clear all output then \"Run All\" -- or it didn't happen\n",
    "    * video narratives: there's text, and there's subtext...\n",
    "    * pause after each \"beat\" -- smile, breathe, allow people to follow you\n",
    "    \"\"\"); nb_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    from pathlib import Path\n",
    "    from pidgin import markdown, conventions\n",
    "    from nbconvert.exporters.python import PythonExporter\n",
    "    from IPython.utils.capture import capture_output\n",
    "    from nbconvert.preprocessors.execute import ExecutePreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Notebooks as a Unit of Thought\n",
       "\n",
       "    exporter = PythonExporter(preprocessors=[markdown.Normalize(), conventions.Normalize(), ExecutePreprocessor()])    \n",
       "    \n",
       "    \n",
       "    def test_nbconvert_script():\n",
       "        with capture_output():\n",
       "            Path('informal_script.py').write_text(exporter.from_filename(__file__)[0])\n",
       "            import informal_script\n",
       "        assert informal_script, \"\"\"The script was not created.\"\"\"\n",
       "        print('nbconvert is complete.')\n",
       "        \n",
       "## Control Flow\n",
       "\n",
       "When running notebooks as scripts there is logic to consider that separates the interactive computing state from the module state.\n",
       "        \n",
       "    (\n",
       "        __name__ == '__main__' \n",
       "        and Path(__file__).parts[-1].startswith('informal.')\n",
       "    ) and test_nbconvert_script()"
      ],
      "text/plain": [
       "# Notebooks as a Unit of Thought\n",
       "\n",
       "    exporter = PythonExporter(preprocessors=[markdown.Normalize(), conventions.Normalize(), ExecutePreprocessor()])    \n",
       "    \n",
       "    \n",
       "    def test_nbconvert_script():\n",
       "        with capture_output():\n",
       "            Path('informal_script.py').write_text(exporter.from_filename(__file__)[0])\n",
       "            import informal_script\n",
       "        assert informal_script, \"\"\"The script was not created.\"\"\"\n",
       "        print('nbconvert is complete.')\n",
       "        \n",
       "## Control Flow\n",
       "\n",
       "When running notebooks as scripts there is logic to consider that separates the interactive computing state from the module state.\n",
       "        \n",
       "    (\n",
       "        __name__ == '__main__' \n",
       "        and Path(__file__).parts[-1].startswith('informal.')\n",
       "    ) and test_nbconvert_script()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbconvert is complete.\n"
     ]
    }
   ],
   "source": [
    "# Notebooks as a Unit of Thought\n",
    "\n",
    "    exporter = PythonExporter(preprocessors=[markdown.Normalize(), conventions.Normalize(), ExecutePreprocessor()])    \n",
    "    \n",
    "    \n",
    "    def test_nbconvert_script():\n",
    "        with capture_output():\n",
    "            Path('informal_script.py').write_text(exporter.from_filename(__file__)[0])\n",
    "            import informal_script\n",
    "        assert informal_script, \"\"\"The script was not created.\"\"\"\n",
    "        print('nbconvert is complete.')\n",
    "        \n",
    "## Control Flow\n",
    "\n",
    "When running notebooks as scripts there is logic to consider that separates the interactive computing state from the module state.\n",
    "        \n",
    "    (\n",
    "        __name__ == '__main__' \n",
    "        and Path(__file__).parts[-1].startswith('informal.')\n",
    "    ) and test_nbconvert_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# `importnb` uses notebooks as modules\n",
       "\n",
       "Since our notebook will __Restart and Run All__ it can be loaded as module.\n",
       "\n",
       "## Interactive computing modules vs. python modules\n",
       "\n",
       "    if __name__ == '__main__':\n",
       "        from importnb import Notebook, reload\n",
       "        %reload_ext pidgin\n",
       "        %pidgin conventions markdown\n",
       "        with Notebook():\n",
       "            try: import informal\n",
       "            except: from . import informal\n",
       "            reload(informal)\n",
       "            assert informal.__file__.endswith('.ipynb')"
      ],
      "text/plain": [
       "# `importnb` uses notebooks as modules\n",
       "\n",
       "Since our notebook will __Restart and Run All__ it can be loaded as module.\n",
       "\n",
       "## Interactive computing modules vs. python modules\n",
       "\n",
       "    if __name__ == '__main__':\n",
       "        from importnb import Notebook, reload\n",
       "        %reload_ext pidgin\n",
       "        %pidgin conventions markdown\n",
       "        with Notebook():\n",
       "            try: import informal\n",
       "            except: from . import informal\n",
       "            reload(informal)\n",
       "            assert informal.__file__.endswith('.ipynb')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `importnb` uses notebooks as modules\n",
    "\n",
    "Since our notebook will __Restart and Run All__ it can be loaded as module.\n",
    "\n",
    "## Interactive computing modules vs. python modules\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        from importnb import Notebook, reload\n",
    "        %reload_ext pidgin\n",
    "        %pidgin conventions markdown\n",
    "        with Notebook():\n",
    "            try: import informal\n",
    "            except: from . import informal\n",
    "            reload(informal)\n",
    "            assert informal.__file__.endswith('.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary\n",
       "\n",
       "---\n",
       "---\n",
       "\n",
       "* ### Interactive computing is informal testing.\n",
       "* ### A hypothesis requires the author to assert something.\n",
       "* ### Notebooks are easy to share, and interactive compute is not.\n",
       "* ### _Informal_ testing does not explicitly test for errors while _formal_ testing does."
      ],
      "text/plain": [
       "# Summary\n",
       "\n",
       "---\n",
       "---\n",
       "\n",
       "* ### Interactive computing is informal testing.\n",
       "* ### A hypothesis requires the author to assert something.\n",
       "* ### Notebooks are easy to share, and interactive compute is not.\n",
       "* ### _Informal_ testing does not explicitly test for errors while _formal_ testing does."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "* ### Interactive computing is informal testing.\n",
    "* ### A hypothesis requires the author to assert something.\n",
    "* ### Notebooks are easy to share, and interactive compute is not.\n",
    "* ### _Informal_ testing does not explicitly test for errors while _formal_ testing does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __[If a notebook is hypothesis then it tests something.](informal.ipynb)__\n",
    "2. ~~[If a notebook is a hypothesis then it can be tested.](formal.ipynb)~~\n",
    "3. ~~[If a notebook is a hypothesis then it will be tested.](continuous.ipynb)~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
