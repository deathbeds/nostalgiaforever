{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Notebook is a Hypothesis\n",
    "\n",
    "1. __[If a notebook is a hypothesis then it tests something.](nostalgiaforever/informal.ipynb)__\n",
    "2. ~~[If a notebook is a hypothesis then it can be formally tested.](nostalgiaforever/formal.ipynb)~~\n",
    "3. ~~[If a notebook is a hypothesis then it will be tested.](nostalgiaforever/social.ipynb)~~\n",
    "\n",
    "[![Data Driven Journalism](https://camo.githubusercontent.com/a8d4be63da2f73339f35839d4c006f080b13104a/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f342f34382f446174615f64726976656e5f6a6f75726e616c69736d5f70726f636573732e6a7067)]()\n",
    "\n",
    "> ### Science is rapidly becoming more relevent in popular culture & modern notebooks are having an impact.  POP CULTURE REFERENCES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    __file__ = globals().get('__file__', 'informal.ipynb')\n",
    "    from IPython import get_ipython\n",
    "    try: \n",
    "        from .util import __ipython__\n",
    "    except: \n",
    "        if __name__ == '__main__':\n",
    "            %reload_ext pidgin\n",
    "            %pidgin conventions markdown \n",
    "\n",
    "        from util import __ipython__\n",
    "        \n",
    "    from graphviz import Source\n",
    "    interactive_computing = Source(\"\"\"digraph {rankdir=\"LR\" layout=\"fdp\" \n",
    "             subgraph cluster_ic { label=\"Interactive Computing\" subgraph cluster_human {label=\"human\" read -> write}\n",
    "                 subgraph cluster_machine {label=\"machine\" eval -> print}\n",
    "                 write -> eval; print -> read}}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __[If a notebook is a hypothesis then it tests something.](nostalgiaforever/informal.ipynb)__\n",
    "\n",
    "* ### If something is a hypothesis then it can by tested.\n",
    "\n",
    "* ### An interactive computing session that tests code or data the first time is the first test.\n",
    "    \n",
    "* ### _Informal_ testing does not explicitly test for errors while _formal_ testing does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Lifecycle of a Notebook Session\n",
       "\n",
       "A notebook session is semi-permanant.\n",
       "\n",
       "---\n",
       "\n",
       "1. $t_{0}$ - *setUp* and __init__ialize the Notebook \n",
       "\n",
       "    ~~Hope~~ Assume that your environment is set up.\n",
       "\n",
       "2. $t_i$   - repeatedly __enter__ and __exit__ the _interactive computing_ session\n",
       "\n",
       "    Lose your mind.\n",
       "\n",
       "3. $t_{final}$ - tearDown the notebook session.\n",
       "\n",
       "    Lose your memory.\n",
       "\n",
       "4. # ðŸ˜µðŸ˜µðŸ˜µðŸ˜µ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    from IPython.display import Markdown\n",
    "    notebook_session = Markdown(\"\"\"# Lifecycle of a Notebook Session\n",
    "\n",
    "    A notebook session is semi-permanant.\n",
    "\n",
    "    ---\n",
    "\n",
    "    1. $t_{0}$ - *setUp* and __init__ialize the Notebook \n",
    "\n",
    "        ~~Hope~~ Assume that your environment is set up.\n",
    "\n",
    "    2. $t_i$   - repeatedly __enter__ and __exit__ the _interactive computing_ session\n",
    "    \n",
    "        Lose your mind.\n",
    "\n",
    "    3. $t_{final}$ - tearDown the notebook session.\n",
    "    \n",
    "        Lose your memory.\n",
    "\n",
    "    4. # ðŸ˜µðŸ˜µðŸ˜µðŸ˜µ\"\"\"); notebook_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ## Sometimes I think the only universal in the computing field is the fetch-execute cycle.\n",
       ">> [Alan Perlis](http://www.cs.yale.edu/homes/perlis-alan/quotes.html)\n",
       "\n",
       "    interactive_computing"
      ],
      "text/plain": [
       "> ## Sometimes I think the only universal in the computing field is the fetch-execute cycle.\n",
       ">> [Alan Perlis](http://www.cs.yale.edu/homes/perlis-alan/quotes.html)\n",
       "\n",
       "    interactive_computing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"225pt\" height=\"185pt\"\n",
       " viewBox=\"0.00 0.00 225.00 185.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 181)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-181 221,-181 221,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\"><title>cluster_ic</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"-0.261883,-0.140888 -0.261883,-177.141 216.738,-177.141 216.738,-0.140888 -0.261883,-0.140888\"/>\n",
       "<text text-anchor=\"middle\" x=\"108.238\" y=\"-161.941\" font-family=\"Times,serif\" font-size=\"14.00\">Interactive Computing</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\"><title>cluster_human</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7.84858,-24.0821 7.84858,-147.082 102.849,-147.082 102.849,-24.0821 7.84858,-24.0821\"/>\n",
       "<text text-anchor=\"middle\" x=\"55.3486\" y=\"-131.882\" font-family=\"Times,serif\" font-size=\"14.00\">human</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\"><title>cluster_machine</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"115.896,-8.08859 115.896,-131.089 208.896,-131.089 208.896,-8.08859 115.896,-8.08859\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.396\" y=\"-115.889\" font-family=\"Times,serif\" font-size=\"14.00\">machine</text>\n",
       "</g>\n",
       "<!-- read -->\n",
       "<g id=\"node1\" class=\"node\"><title>read</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"47.8785\" cy=\"-99.1761\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.8785\" y=\"-94.9761\" font-family=\"Times,serif\" font-size=\"14.00\">read</text>\n",
       "</g>\n",
       "<!-- write -->\n",
       "<g id=\"node2\" class=\"node\"><title>write</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"44.55\" cy=\"-49.6309\" rx=\"28.0565\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"44.55\" y=\"-45.4309\" font-family=\"Times,serif\" font-size=\"14.00\">write</text>\n",
       "</g>\n",
       "<!-- read&#45;&gt;write -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>read&#45;&gt;write</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M46.658,-81.0086C46.5947,-80.0662 46.5304,-79.11 46.4657,-78.146\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"49.9329,-77.539 45.7704,-67.7962 42.9486,-78.0083 49.9329,-77.539\"/>\n",
       "</g>\n",
       "<!-- eval -->\n",
       "<g id=\"node3\" class=\"node\"><title>eval</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170.866\" cy=\"-33.9945\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.866\" y=\"-29.7945\" font-family=\"Times,serif\" font-size=\"14.00\">eval</text>\n",
       "</g>\n",
       "<!-- write&#45;&gt;eval -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>write&#45;&gt;eval</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.5837,-46.1607C90.6971,-43.9184 114.462,-40.9766 134.086,-38.5475\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.714,-41.9965 144.208,-37.2945 133.854,-35.0496 134.714,-41.9965\"/>\n",
       "</g>\n",
       "<!-- print -->\n",
       "<g id=\"node4\" class=\"node\"><title>print</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.195\" cy=\"-83.5398\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.195\" y=\"-79.3398\" font-family=\"Times,serif\" font-size=\"14.00\">print</text>\n",
       "</g>\n",
       "<!-- eval&#45;&gt;print -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>eval&#45;&gt;print</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.087,-52.162C172.15,-53.1045 172.214,-54.0607 172.279,-55.0246\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.812,-55.6316 172.974,-65.3745 175.796,-55.1624 168.812,-55.6316\"/>\n",
       "</g>\n",
       "<!-- print&#45;&gt;read -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>print&#45;&gt;read</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M147.406,-86.8559C129.152,-89.1155 104.749,-92.1363 84.6753,-94.6212\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.1226,-91.1628 74.6283,-95.8649 84.9826,-98.1098 84.1226,-91.1628\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x10cd5bf60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "> ## Sometimes I think the only universal in the computing field is the fetch-execute cycle.\n",
    ">> [Alan Perlis](http://www.cs.yale.edu/homes/perlis-alan/quotes.html)\n",
    "\n",
    "    interactive_computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# [\"Literate computing\" and computational reproducibility: IPython in the age of data-driven journalism](http://blog.fperez.org/2013/04/literate-computing-and-computational.html)\n",
       "\n",
       "> Our job with Jupyter~~IPython~~ is to think deeply about questions regarding the intersection of _**computing, data and science**_, but it's clear to me at this point that we can contribute in contexts beyond pure scientific research. I hope we'll be able to provide folks who have a _**direct intersection with the public**_, such as journalists, with tools that help a more informed and productive debate."
      ],
      "text/plain": [
       "# [\"Literate computing\" and computational reproducibility: IPython in the age of data-driven journalism](http://blog.fperez.org/2013/04/literate-computing-and-computational.html)\n",
       "\n",
       "> Our job with Jupyter~~IPython~~ is to think deeply about questions regarding the intersection of _**computing, data and science**_, but it's clear to me at this point that we can contribute in contexts beyond pure scientific research. I hope we'll be able to provide folks who have a _**direct intersection with the public**_, such as journalists, with tools that help a more informed and productive debate."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [\"Literate computing\" and computational reproducibility: IPython in the age of data-driven journalism](http://blog.fperez.org/2013/04/literate-computing-and-computational.html)\n",
    "\n",
    "> Our job with Jupyter~~IPython~~ is to think deeply about questions regarding the intersection of _**computing, data and science**_, but it's clear to me at this point that we can contribute in contexts beyond pure scientific research. I hope we'll be able to provide folks who have a _**direct intersection with the public**_, such as journalists, with tools that help a more informed and productive debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"302pt\" height=\"67pt\"\n",
       " viewBox=\"0.00 0.00 302.12 67.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 63)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-63 298.122,-63 298.122,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- science -->\n",
       "<g id=\"node2\" class=\"node\"><title>science</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"126.128\" cy=\"-41\" rx=\"36.2558\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.128\" y=\"-36.8\" font-family=\"Times,serif\" font-size=\"14.00\">science</text>\n",
       "</g>\n",
       "<!-- data&#45;&#45;science -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>data&#45;&#45;science</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.7607,-23.8634C65.0132,-26.7648 79.9513,-30.3022 93.0668,-33.4079\"/>\n",
       "</g>\n",
       "<!-- computing -->\n",
       "<g id=\"node3\" class=\"node\"><title>computing</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"246.189\" cy=\"-18\" rx=\"47.8668\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"246.189\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">computing</text>\n",
       "</g>\n",
       "<!-- science&#45;&#45;computing -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>science&#45;&#45;computing</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.014,-34.5932C173.387,-31.988 189.003,-28.9457 203.186,-26.1828\"/>\n",
       "</g>\n",
       "<!-- computing&#45;&#45;data -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>computing&#45;&#45;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.708,-15.363C186.828,-14.7976 174.072,-14.2848 162.255,-14 130.151,-13.2262 122.097,-12.9657 90,-14 78.1413,-14.3821 65.0265,-15.1744 53.9246,-15.9538\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x10cefa550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "    graph {rankdir=\"LR\"; data--science--computing--data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Literate Programming\n",
       "\n",
       "> ## Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.\n",
       "> ### ... surely nobody wants to admit writing an illiterate program.\n",
       "\n",
       ">> [Donald Knuth]({{computing.people['knuth']}}) - [Literate Programming](http://roxygen.org/knuth-literate-programming.pdf)"
      ],
      "text/plain": [
       "# Literate Programming\n",
       "\n",
       "> ## Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.\n",
       "> ### ... surely nobody wants to admit writing an illiterate program.\n",
       "\n",
       ">> [Donald Knuth]({{computing.people['knuth']}}) - [Literate Programming](http://roxygen.org/knuth-literate-programming.pdf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Literate Programming\n",
    "\n",
    "> ## Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.\n",
    "> ### ... surely nobody wants to admit writing an illiterate program.\n",
    "\n",
    ">> [Donald Knuth]({{computing.people['knuth']}}) - [Literate Programming](http://roxygen.org/knuth-literate-programming.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Literate Programming <big>&lowast;</big> Interactive Computing = Literate Computing"
      ],
      "text/plain": [
       "# Literate Programming <big>&lowast;</big> Interactive Computing = Literate Computing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Literate Programming <big>&lowast;</big> Interactive Computing = Literate Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"551pt\" height=\"152pt\"\n",
       " viewBox=\"0.00 0.00 551.17 152.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 148)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-148 547.166,-148 547.166,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\"><title>clusterc</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"254.244,-8 254.244,-136 535.166,-136 535.166,-8 254.244,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"394.705\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">literate computing</text>\n",
       "</g>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"500.166\" cy=\"-61\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"500.166\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- interactive computing -->\n",
       "<g id=\"node2\" class=\"node\"><title>interactive computing</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"349.705\" cy=\"-88\" rx=\"87.4225\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"349.705\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\">interactive computing</text>\n",
       "</g>\n",
       "<!-- data&#45;&gt;interactive computing -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>data&#45;&gt;interactive computing</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M472.966,-60.4734C455.064,-62.4422 430.629,-66.4507 408.309,-70.9265\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"407.318,-67.5574 398.234,-73.0102 408.736,-74.4124 407.318,-67.5574\"/>\n",
       "</g>\n",
       "<!-- literate programming -->\n",
       "<g id=\"node3\" class=\"node\"><title>literate programming</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"349.705\" cy=\"-34\" rx=\"85.0085\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"349.705\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\">literate programming</text>\n",
       "</g>\n",
       "<!-- data&#45;&gt;literate programming -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>data&#45;&gt;literate programming</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M476.618,-51.8899C465.809,-49.0275 452.098,-45.9836 437.728,-43.1663\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"438.179,-39.6895 427.701,-41.2571 436.87,-46.5659 438.179,-39.6895\"/>\n",
       "</g>\n",
       "<!-- interactive computing&#45;&gt;data -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>interactive computing&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429.339,-80.4386C442.624,-77.9587 455.72,-75.2239 466.917,-72.5453\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"467.771,-75.9397 476.618,-70.1101 466.067,-69.1504 467.771,-75.9397\"/>\n",
       "</g>\n",
       "<!-- machines -->\n",
       "<g id=\"node4\" class=\"node\"><title>machines</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"182.741\" cy=\"-88\" rx=\"43.506\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.741\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\">machines</text>\n",
       "</g>\n",
       "<!-- interactive computing&#45;&gt;machines -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>interactive computing&#45;&gt;machines</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261.875,-88C253.252,-88 244.692,-88 236.574,-88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"236.557,-84.5001 226.557,-88 236.557,-91.5001 236.557,-84.5001\"/>\n",
       "</g>\n",
       "<!-- literate programming&#45;&gt;data -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>literate programming&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M397.935,-48.9258C418.974,-53.4248 443.363,-57.7127 462.931,-60.303\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.616,-63.7905 472.966,-61.5266 463.463,-56.8419 462.616,-63.7905\"/>\n",
       "</g>\n",
       "<!-- literate programming&#45;&gt;machines -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>literate programming&#45;&gt;machines</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.485,-48.0452C282.676,-51.9991 267.834,-56.465 254.244,-61 244.359,-64.2983 233.815,-68.1519 223.973,-71.8978\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.488,-68.7194 214.417,-75.5833 225.007,-75.2506 222.488,-68.7194\"/>\n",
       "</g>\n",
       "<!-- people -->\n",
       "<g id=\"node5\" class=\"node\"><title>people</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"182.741\" cy=\"-34\" rx=\"33.8596\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.741\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\">people</text>\n",
       "</g>\n",
       "<!-- literate programming&#45;&gt;people -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>literate programming&#45;&gt;people</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M264.29,-34C251.302,-34 238.378,-34 226.806,-34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.597,-30.5001 216.597,-34 226.597,-37.5001 226.597,-30.5001\"/>\n",
       "</g>\n",
       "<!-- ðŸ™‰ðŸ™ˆðŸ™Š -->\n",
       "<g id=\"node6\" class=\"node\"><title>ðŸ™‰ðŸ™ˆðŸ™Š</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"51.6188\" cy=\"-61\" rx=\"51.7379\" ry=\"21.7969\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.6188\" y=\"-61.2844\" font-family=\"Times,serif\" font-size=\"14.00\">ðŸ™‰ðŸ™ˆðŸ™Š</text>\n",
       "</g>\n",
       "<!-- machines&#45;&gt;ðŸ™‰ðŸ™ˆðŸ™Š -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>machines&#45;&gt;ðŸ™‰ðŸ™ˆðŸ™Š</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M143.698,-80.0451C132.54,-77.7118 120.102,-75.1111 108.092,-72.5998\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.647,-69.1401 98.1423,-70.5192 107.214,-75.992 108.647,-69.1401\"/>\n",
       "</g>\n",
       "<!-- people&#45;&gt;ðŸ™‰ðŸ™ˆðŸ™Š -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>people&#45;&gt;ðŸ™‰ðŸ™ˆðŸ™Š</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.141,-40.3986C138.295,-43.0847 122.941,-46.2952 108.222,-49.3732\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107.243,-46.0021 98.1707,-51.4749 108.675,-52.8539 107.243,-46.0021\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x10cefa668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "    digraph {rankdir=\"RL\"; subgraph clusterc{ label=\"literate computing\"; data->\"interactive computing\" ->data -> \"literate programming\" ->data} {\"interactive computing\" \"literate programming\"} -> machines \"literate programming\" -> people {machines people} -> ðŸ™‰ðŸ™ˆðŸ™Š} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The Scientist is a Context Manager\n",
       "    \n",
       "    from contextlib import contextmanager\n",
       "    @contextmanager\n",
       "    def theScientist(*independent_arguments, response=None, who: ['Human', 'Machine'] = 'Human', **experiment_settings):\n",
       "        \"\"\"A hypothesis requires an experimental design.\n",
       "        \"\"\"\n",
       "        f\"\"\"Setup the experiment with {independent_arguments} and {experiment_settings}\"\"\"\n",
       "        yield response\n",
       "        f\"\"\"Clean up and communicate your results to {who}.\"\"\""
      ],
      "text/plain": [
       "# The Scientist is a Context Manager\n",
       "    \n",
       "    from contextlib import contextmanager\n",
       "    @contextmanager\n",
       "    def theScientist(*independent_arguments, response=None, who: ['Human', 'Machine'] = 'Human', **experiment_settings):\n",
       "        \"\"\"A hypothesis requires an experimental design.\n",
       "        \"\"\"\n",
       "        f\"\"\"Setup the experiment with {independent_arguments} and {experiment_settings}\"\"\"\n",
       "        yield response\n",
       "        f\"\"\"Clean up and communicate your results to {who}.\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The Scientist is a Context Manager\n",
    "    \n",
    "    from contextlib import contextmanager\n",
    "    @contextmanager\n",
    "    def theScientist(*independent_arguments, response=None, who: ['Human', 'Machine'] = 'Human', **experiment_settings):\n",
    "        \"\"\"A hypothesis requires an experimental design.\n",
    "        \"\"\"\n",
    "        f\"\"\"Setup the experiment with {independent_arguments} and {experiment_settings}\"\"\"\n",
    "        yield response\n",
    "        f\"\"\"Clean up and communicate your results to {who}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "---\n",
       "---\n",
       "\n",
       "# Statistical hypothesis testing is for computers to help people.\n",
       "\n",
       "---\n",
       "# Design of experiments are for people testing hypotheses.\n",
       "\n",
       "---\n",
       "---\n",
       "---"
      ],
      "text/plain": [
       "---\n",
       "---\n",
       "---\n",
       "\n",
       "# Statistical hypothesis testing is for computers to help people.\n",
       "\n",
       "---\n",
       "# Design of experiments are for people testing hypotheses.\n",
       "\n",
       "---\n",
       "---\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# Statistical hypothesis testing is for computers to help people.\n",
    "\n",
    "---\n",
    "# Design of experiments are for people testing hypotheses.\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# We have style guides for programming.\n",
       "\n",
       "* [Zen of Python](https://www.python.org/dev/peps/pep-0020/)\n",
       "* [Zen of Numpy](http://technicaldiscovery.blogspot.com/2010/11/zen-of-numpy.html)\n",
       "* [Zen of SymPy](https://www.google.com/search?q=zen+of+sympy&oq=zen+of+sympy&aqs=chrome..69i57.1863j0j7&sourceid=chrome&ie=UTF-8)\n",
       "* ~~Zen of Notebooks~~"
      ],
      "text/plain": [
       "# We have style guides for programming.\n",
       "\n",
       "* [Zen of Python](https://www.python.org/dev/peps/pep-0020/)\n",
       "* [Zen of Numpy](http://technicaldiscovery.blogspot.com/2010/11/zen-of-numpy.html)\n",
       "* [Zen of SymPy](https://www.google.com/search?q=zen+of+sympy&oq=zen+of+sympy&aqs=chrome..69i57.1863j0j7&sourceid=chrome&ie=UTF-8)\n",
       "* ~~Zen of Notebooks~~"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We have style guides for programming.\n",
    "\n",
    "* [Zen of Python](https://www.python.org/dev/peps/pep-0020/)\n",
    "* [Zen of Numpy](http://technicaldiscovery.blogspot.com/2010/11/zen-of-numpy.html)\n",
    "* [Zen of SymPy](https://www.google.com/search?q=zen+of+sympy&oq=zen+of+sympy&aqs=chrome..69i57.1863j0j7&sourceid=chrome&ie=UTF-8)\n",
    "* ~~Zen of Notebooks~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ## What we learned about teaching with notebooks (in Oriole)\n",
       ">> [Paco Nathan - Oriole: a new learning medium based on Jupyter + Docker](http://nbviewer.jupyter.org/github/jupyterday-atlanta-2016/oriole_jupyterday_atl/blob/master/oriole_talk.ipynb#What-we-learned-about-teaching-with-notebooks)"
      ],
      "text/plain": [
       "> ## What we learned about teaching with notebooks (in Oriole)\n",
       ">> [Paco Nathan - Oriole: a new learning medium based on Jupyter + Docker](http://nbviewer.jupyter.org/github/jupyterday-atlanta-2016/oriole_jupyterday_atl/blob/master/oriole_talk.ipynb#What-we-learned-about-teaching-with-notebooks)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "> ## What we learned about teaching with notebooks (in Oriole)\n",
    ">> [Paco Nathan - Oriole: a new learning medium based on Jupyter + Docker](http://nbviewer.jupyter.org/github/jupyterday-atlanta-2016/oriole_jupyterday_atl/blob/master/oriole_talk.ipynb#What-we-learned-about-teaching-with-notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "* ## focus on a concise \"unit of thought\"\n",
       "* invest the time and editorial effort to create a good introduction\n",
       "* keep your narrative simple and reasonably linear\n",
       "* \"chunk\" both the text and the code into understandable parts\n",
       "* alternate between text, code, output, further links, etc.\n",
       "* leverage markdown by providing interesting links for background, deep-dive, etc.\n",
       "* code cells should not be long, < 10 lines\n",
       "* code cells must show that they've run, producing at least *some* output \n",
       "* load data from the container, not the network\n",
       "* ## clear all output then \"Run All\" -- or it didn't happen\n",
       "* video narratives: there's text, and there's subtext...\n",
       "* pause after each \"beat\" -- smile, breathe, allow people to follow you\n"
      ],
      "text/plain": [
       "* ## focus on a concise \"unit of thought\"\n",
       "* invest the time and editorial effort to create a good introduction\n",
       "* keep your narrative simple and reasonably linear\n",
       "* \"chunk\" both the text and the code into understandable parts\n",
       "* alternate between text, code, output, further links, etc.\n",
       "* leverage markdown by providing interesting links for background, deep-dive, etc.\n",
       "* code cells should not be long, < 10 lines\n",
       "* code cells must show that they've run, producing at least *some* output \n",
       "* load data from the container, not the network\n",
       "* ## clear all output then \"Run All\" -- or it didn't happen\n",
       "* video narratives: there's text, and there's subtext...\n",
       "* pause after each \"beat\" -- smile, breathe, allow people to follow you"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    nb_style = Markdown(\"\"\"* ## focus on a concise \"unit of thought\"\n",
    "    * invest the time and editorial effort to create a good introduction\n",
    "    * keep your narrative simple and reasonably linear\n",
    "    * \"chunk\" both the text and the code into understandable parts\n",
    "    * alternate between text, code, output, further links, etc.\n",
    "    * leverage markdown by providing interesting links for background, deep-dive, etc.\n",
    "    * code cells should not be long, < 10 lines\n",
    "    * code cells must show that they've run, producing at least *some* output \n",
    "    * load data from the container, not the network\n",
    "    * ## clear all output then \"Run All\" -- or it didn't happen\n",
    "    * video narratives: there's text, and there's subtext...\n",
    "    * pause after each \"beat\" -- smile, breathe, allow people to follow you\n",
    "    \"\"\"); nb_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    from pathlib import Path\n",
    "    from pidgin import markdown, conventions\n",
    "    from nbconvert.exporters.python import PythonExporter\n",
    "    from IPython.utils.capture import capture_output\n",
    "    from nbconvert.preprocessors.execute import ExecutePreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Notebooks as a Unit of Thought\n",
       "\n",
       "    exporter = PythonExporter(preprocessors=[markdown.Normalize(), conventions.Normalize(), ExecutePreprocessor()])    \n",
       "    \n",
       "    if (\n",
       "        __name__ == '__main__' \n",
       "        and Path(__file__).parts[-1].startswith('informal.')\n",
       "    ):\n",
       "        with capture_output():\n",
       "            Path('informal_script.py').write_text(exporter.from_filename(__file__)[0])\n",
       "            import informal_script\n",
       "        assert informal_script, \"\"\"The script was not created.\"\"\"\n",
       "        print('nbconvert is complete.')"
      ],
      "text/plain": [
       "# Notebooks as a Unit of Thought\n",
       "\n",
       "    exporter = PythonExporter(preprocessors=[markdown.Normalize(), conventions.Normalize(), ExecutePreprocessor()])    \n",
       "    \n",
       "    if (\n",
       "        __name__ == '__main__' \n",
       "        and Path(__file__).parts[-1].startswith('informal.')\n",
       "    ):\n",
       "        with capture_output():\n",
       "            Path('informal_script.py').write_text(exporter.from_filename(__file__)[0])\n",
       "            import informal_script\n",
       "        assert informal_script, \"\"\"The script was not created.\"\"\"\n",
       "        print('nbconvert is complete.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbconvert is complete.\n"
     ]
    }
   ],
   "source": [
    "# Notebooks as a Unit of Thought\n",
    "\n",
    "    exporter = PythonExporter(preprocessors=[markdown.Normalize(), conventions.Normalize(), ExecutePreprocessor()])    \n",
    "    \n",
    "    if (\n",
    "        __name__ == '__main__' \n",
    "        and Path(__file__).parts[-1].startswith('informal.')\n",
    "    ):\n",
    "        with capture_output():\n",
    "            Path('informal_script.py').write_text(exporter.from_filename(__file__)[0])\n",
    "            import informal_script\n",
    "        assert informal_script, \"\"\"The script was not created.\"\"\"\n",
    "        print('nbconvert is complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# `importnb` uses notebooks as modules\n",
       "\n",
       "Since our notebook will __Restart and Run All__ it can be loaded as module.\n",
       "\n",
       "## Control Flow for Notebook Modules\n",
       "\n",
       "    from importnb import Notebook, reload\n",
       "    %reload_ext pidgin\n",
       "    %pidgin conventions markdown\n",
       "    with Notebook():\n",
       "        informal = reload(__import__('informal'))\n",
       "        assert informal.__file__.endswith('.ipynb')"
      ],
      "text/plain": [
       "# `importnb` uses notebooks as modules\n",
       "\n",
       "Since our notebook will __Restart and Run All__ it can be loaded as module.\n",
       "\n",
       "## Control Flow for Notebook Modules\n",
       "\n",
       "    from importnb import Notebook, reload\n",
       "    %reload_ext pidgin\n",
       "    %pidgin conventions markdown\n",
       "    with Notebook():\n",
       "        informal = reload(__import__('informal'))\n",
       "        assert informal.__file__.endswith('.ipynb')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `importnb` uses notebooks as modules\n",
    "\n",
    "Since our notebook will __Restart and Run All__ it can be loaded as module.\n",
    "\n",
    "## Control Flow for Notebook Modules\n",
    "\n",
    "    from importnb import Notebook, reload\n",
    "    %reload_ext pidgin\n",
    "    %pidgin conventions markdown\n",
    "    with Notebook():\n",
    "        informal = reload(__import__('informal'))\n",
    "        assert informal.__file__.endswith('.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart and run all as a watcher.\n",
    "\n",
    "    watchmedo tricks tricks.yml\n",
    "    \n",
    "...using [watchdog](https://github.com/gorakhargosh/watchdog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary\n",
       "\n",
       "---\n",
       "---\n",
       "\n",
       "* ### Interactive computing is informal testing.\n",
       "* ### A hypothesis requires the author to assert something.\n",
       "* ### Notebooks are easy to share, and interactive compute is not."
      ],
      "text/plain": [
       "# Summary\n",
       "\n",
       "---\n",
       "---\n",
       "\n",
       "* ### Interactive computing is informal testing.\n",
       "* ### A hypothesis requires the author to assert something.\n",
       "* ### Notebooks are easy to share, and interactive compute is not."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "* ### Interactive computing is informal testing.\n",
    "* ### A hypothesis requires the author to assert something.\n",
    "* ### Notebooks are easy to share, and interactive compute is not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
