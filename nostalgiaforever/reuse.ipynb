{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing `importing` and `testing`\n",
    "\n",
    "`importing` and `testing` contain tests that can be imported and reused by other testing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from IPython import get_ipython\n",
    "    o = __name__ == '__main__'\n",
    "    with __import__('importnb').Notebook():\n",
    "        try: from .util import __ipython__\n",
    "        except:\n",
    "            if o: \n",
    "                %reload_ext pidgin\n",
    "                %pidgin markdown conventions\n",
    "            from util import __ipython__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<hr/><hr/><hr/><hr/><hr/>\n",
       "\n",
       "# This notebook - `reuse.ipynb` - imports itself `testing`, `importing`, and `reuse`\n",
       "    \n",
       "    from importnb import Notebook, reload\n",
       "    with Notebook():\n",
       "        try:\n",
       "            import importing, testing, reuse\n",
       "        except:\n",
       "            from . import importing, testing, reuse\n",
       "        "
      ],
      "text/plain": [
       "<hr/><hr/><hr/><hr/><hr/>\n",
       "\n",
       "# This notebook - `reuse.ipynb` - imports itself `testing`, `importing`, and `reuse`\n",
       "    \n",
       "    from importnb import Notebook, reload\n",
       "    with Notebook():\n",
       "        try:\n",
       "            import importing, testing, reuse\n",
       "        except:\n",
       "            from . import importing, testing, reuse\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "<hr/><hr/><hr/><hr/><hr/>\n",
    "\n",
    "# This notebook - `reuse.ipynb` - imports itself `testing`, `importing`, and `reuse`\n",
    "    \n",
    "    from importnb import Notebook, reload\n",
    "    with Notebook():\n",
    "        try:\n",
    "            import importing, testing, reuse\n",
    "        except:\n",
    "            from . import importing, testing, reuse\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"http://doc.pytest.org/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10d0022e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "    http://doc.pytest.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    import pytest\n",
       "    if __name__ == '__main__':\n",
       "        pytest.main([\n",
       "            getattr(object, '__file__') for object in (importing, testing)\n",
       "        ] + '-p no:pytest-importnb'.split())"
      ],
      "text/plain": [
       "    import pytest\n",
       "    if __name__ == '__main__':\n",
       "        pytest.main([\n",
       "            getattr(object, '__file__') for object in (importing, testing)\n",
       "        ] + '-p no:pytest-importnb'.split())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
      "benchmark: 3.1.1 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\n",
      "rootdir: /Users/tonyfast/ahypothesis, inifile:\n",
      "plugins: cov-2.5.1, benchmark-3.1.1, hypothesis-3.56.5, nostalgiaforever-0.0.1\n",
      "collected 4 items\n",
      "\n",
      "importing.ipynb ..                                                       [ 50%]\n",
      "testing.ipynb ..                                                         [100%]\n",
      "\n",
      "=============================== warnings summary ===============================\n",
      "None\n",
      "  Module already imported so cannot be rewritten: hypothesis\n",
      "\n",
      "-- Docs: http://doc.pytest.org/en/latest/warnings.html\n",
      "===================== 4 passed, 1 warnings in 0.06 seconds =====================\n"
     ]
    }
   ],
   "source": [
    "    import pytest\n",
    "    if __name__ == '__main__':\n",
    "        pytest.main([\n",
    "            getattr(object, '__file__') for object in (importing, testing)\n",
    "        ] + '-p no:pytest-importnb'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# [Pytest plugins](https://docs.pytest.org/en/2.7.3/plugins_index/index.html)\n",
       "\n",
       "## `pytest-importnb` \n",
       "\n",
       "Discovers notebooks as pytest python modules.  This idea builds off of [pytest-ipynb](https://github.com/zonca/pytest-ipynb/tree/master/pytest_ipynb), [nbval](https://github.com/computationalmodelling/nbval), and [ipynb](https://github.com/ipython/ipynb/tree/master/ipynb)."
      ],
      "text/plain": [
       "# [Pytest plugins](https://docs.pytest.org/en/2.7.3/plugins_index/index.html)\n",
       "\n",
       "## `pytest-importnb` \n",
       "\n",
       "Discovers notebooks as pytest python modules.  This idea builds off of [pytest-ipynb](https://github.com/zonca/pytest-ipynb/tree/master/pytest_ipynb), [nbval](https://github.com/computationalmodelling/nbval), and [ipynb](https://github.com/ipython/ipynb/tree/master/ipynb)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [Pytest plugins](https://docs.pytest.org/en/2.7.3/plugins_index/index.html)\n",
    "\n",
    "## `pytest-importnb` \n",
    "\n",
    "Discovers notebooks as pytest python modules.  This idea builds off of [pytest-ipynb](https://github.com/zonca/pytest-ipynb/tree/master/pytest_ipynb), [nbval](https://github.com/computationalmodelling/nbval), and [ipynb](https://github.com/ipython/ipynb/tree/master/ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## `pytest-benchmark`\n",
       "\n",
       "---\n",
       "    \n",
       "### Compare a `numpy` function and a `numba`\n",
       "\n",
       "    def sum2d(arr):\n",
       "        M, N = arr.shape\n",
       "        result = 0.0\n",
       "        for i in range(M):\n",
       "            for j in range(N):\n",
       "                result += arr[i,j]\n",
       "        return result\n",
       "    \n",
       "---    \n",
       "\n",
       "    def test_py(benchmark):\n",
       "        from numpy import arange\n",
       "        benchmark(sum2d, arange(100).reshape(10,10))\n",
       "\n",
       "    try:\n",
       "        from numba import jit\n",
       "        from numpy import arange\n",
       "        def test_jit(benchmark):\n",
       "            benchmark(jit(sum2d), arange(100).reshape(10,10))\n",
       "    except: ..."
      ],
      "text/plain": [
       "## `pytest-benchmark`\n",
       "\n",
       "---\n",
       "    \n",
       "### Compare a `numpy` function and a `numba`\n",
       "\n",
       "    def sum2d(arr):\n",
       "        M, N = arr.shape\n",
       "        result = 0.0\n",
       "        for i in range(M):\n",
       "            for j in range(N):\n",
       "                result += arr[i,j]\n",
       "        return result\n",
       "    \n",
       "---    \n",
       "\n",
       "    def test_py(benchmark):\n",
       "        from numpy import arange\n",
       "        benchmark(sum2d, arange(100).reshape(10,10))\n",
       "\n",
       "    try:\n",
       "        from numba import jit\n",
       "        from numpy import arange\n",
       "        def test_jit(benchmark):\n",
       "            benchmark(jit(sum2d), arange(100).reshape(10,10))\n",
       "    except: ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## `pytest-benchmark`\n",
    "\n",
    "---\n",
    "    \n",
    "### Compare a `numpy` function and a `numba`\n",
    "\n",
    "    def sum2d(arr):\n",
    "        M, N = arr.shape\n",
    "        result = 0.0\n",
    "        for i in range(M):\n",
    "            for j in range(N):\n",
    "                result += arr[i,j]\n",
    "        return result\n",
    "    \n",
    "---    \n",
    "\n",
    "    def test_py(benchmark):\n",
    "        from numpy import arange\n",
    "        benchmark(sum2d, arange(100).reshape(10,10))\n",
    "\n",
    "    try:\n",
    "        from numba import jit\n",
    "        from numpy import arange\n",
    "        def test_jit(benchmark):\n",
    "            benchmark(jit(sum2d), arange(100).reshape(10,10))\n",
    "    except: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Run the benchmark tests\n",
       "    \n",
       "    import pytest\n",
       "    if __name__ == '__main__':\n",
       "        pytest.main([\n",
       "            getattr(object, '__file__') for object in (importing, testing, reuse)\n",
       "        ] + '-p no:pytest-importnb'.split())"
      ],
      "text/plain": [
       "# Run the benchmark tests\n",
       "    \n",
       "    import pytest\n",
       "    if __name__ == '__main__':\n",
       "        pytest.main([\n",
       "            getattr(object, '__file__') for object in (importing, testing, reuse)\n",
       "        ] + '-p no:pytest-importnb'.split())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.6.3, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
      "benchmark: 3.1.1 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\n",
      "rootdir: /Users/tonyfast/ahypothesis, inifile:\n",
      "plugins: cov-2.5.1, benchmark-3.1.1, hypothesis-3.56.5, nostalgiaforever-0.0.1\n",
      "collected 6 items\n",
      "\n",
      "importing.ipynb ..                                                       [ 33%]\n",
      "testing.ipynb ..                                                         [ 66%]\n",
      "reuse.ipynb ..                                                           [100%]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------- benchmark: 2 tests ----------------------------------------------------------------------------------------------\n",
      "Name (time in ns)             Min                     Max                   Mean                StdDev                 Median                 IQR            Outliers  OPS (Kops/s)            Rounds  Iterations\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_jit                 427.0005 (1.0)        2,296.9980 (1.0)         720.7148 (1.0)        696.6214 (1.0)         439.9990 (1.0)       95.2505 (1.0)           1;1    1,387.5114 (1.0)           7           1\n",
      "test_py               24,965.0002 (58.47)    100,574.0014 (43.78)    28,153.6233 (39.06)    7,505.5879 (10.77)    25,869.0015 (58.79)    847.2489 (8.89)       57;137       35.5194 (0.03)        847           1\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Legend:\n",
      "  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.\n",
      "  OPS: Operations Per Second, computed as 1 / Mean\n",
      "=============================== warnings summary ===============================\n",
      "None\n",
      "  Module already imported so cannot be rewritten: pytest_cov\n",
      "  Module already imported so cannot be rewritten: pytest_benchmark\n",
      "  Module already imported so cannot be rewritten: hypothesis\n",
      "  Module already imported so cannot be rewritten: nostalgiaforever\n",
      "\n",
      "-- Docs: http://doc.pytest.org/en/latest/warnings.html\n",
      "===================== 6 passed, 4 warnings in 1.45 seconds =====================\n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark tests\n",
    "    \n",
    "    import pytest\n",
    "    if __name__ == '__main__':\n",
    "        pytest.main([\n",
    "            getattr(object, '__file__') for object in (importing, testing, reuse)\n",
    "        ] + '-p no:pytest-importnb'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# `hypothesis` has the best API in all of Python\n",
       "\n",
       "    from hypothesis import given, assume, infer, HealthCheck, settings #\n",
       "\n",
       "\n",
       "    \n",
       "    @given(a=infer)\n",
       "    @settings(suppress_health_check=[HealthCheck.return_value])\n",
       "    def test_all_the_strings(a:str):\n",
       "        \"\"\"hypothesis will infer a strategy to test many strings!\n",
       "        \n",
       "        Use type annotations and üèÜüèÜüèÜüèÜüèÜ!\n",
       "        \"\"\"\n",
       "#         print(a)\n",
       "#         assert a\n",
       "        return a\n",
       "\n",
       "    if __name__ == '__main__':\n",
       "        test_all_the_strings()"
      ],
      "text/plain": [
       "# `hypothesis` has the best API in all of Python\n",
       "\n",
       "    from hypothesis import given, assume, infer, HealthCheck, settings #\n",
       "\n",
       "\n",
       "    \n",
       "    @given(a=infer)\n",
       "    @settings(suppress_health_check=[HealthCheck.return_value])\n",
       "    def test_all_the_strings(a:str):\n",
       "        \"\"\"hypothesis will infer a strategy to test many strings!\n",
       "        \n",
       "        Use type annotations and üèÜüèÜüèÜüèÜüèÜ!\n",
       "        \"\"\"\n",
       "#         print(a)\n",
       "#         assert a\n",
       "        return a\n",
       "\n",
       "    if __name__ == '__main__':\n",
       "        test_all_the_strings()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `hypothesis` has the best API in all of Python\n",
    "\n",
    "    from hypothesis import given, assume, infer, HealthCheck, settings #\n",
    "\n",
    "\n",
    "    \n",
    "    @given(a=infer)\n",
    "    @settings(suppress_health_check=[HealthCheck.return_value])\n",
    "    def test_all_the_strings(a:str):\n",
    "        \"\"\"hypothesis will infer a strategy to test many strings!\n",
    "        \n",
    "        Use type annotations and üèÜüèÜüèÜüèÜüèÜ!\n",
    "        \"\"\"\n",
    "#         print(a)\n",
    "#         assert a\n",
    "        return a\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        test_all_the_strings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    http://tox.readthedocs.io/en/latest/example/pytest.html"
      ],
      "text/plain": [
       "    http://tox.readthedocs.io/en/latest/example/pytest.html"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"http://tox.readthedocs.io/en/latest/example/pytest.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10d482f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    http://tox.readthedocs.io/en/latest/example/pytest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# [Travis](https://travis-ci.org/deathbeds/nostalgiaforever)\n",
       "\n",
       "\n",
       "https://github.com/travis-ci/dpl\n",
       "    \n",
       "`travis setup pypi`\n",
       "`travis setup pages`\n",
       "* The readme creates our documentation\n"
      ],
      "text/plain": [
       "# [Travis](https://travis-ci.org/deathbeds/nostalgiaforever)\n",
       "\n",
       "\n",
       "https://github.com/travis-ci/dpl\n",
       "    \n",
       "`travis setup pypi`\n",
       "`travis setup pages`\n",
       "* The readme creates our documentation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [Travis](https://travis-ci.org/deathbeds/nostalgiaforever)\n",
    "\n",
    "\n",
    "https://github.com/travis-ci/dpl\n",
    "    \n",
    "`travis setup pypi`\n",
    "`travis setup pages`\n",
    "* The readme creates our documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary \n",
       "\n",
       "* tests can be designed incrementally across notebooks and aggregated."
      ],
      "text/plain": [
       "# Summary \n",
       "\n",
       "* tests can be designed incrementally across notebooks and aggregated."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary \n",
    "\n",
    "* tests can be designed incrementally across notebooks and aggregated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travis Dee-Pee-Ell Deployments\n",
    "\n",
    "\n",
    "# [Github](https://pip.pypa.io/en/stable/reference/pip_install/#vcs-support)\n",
    "\n",
    "## Pages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pypi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuse the python code you write in notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
