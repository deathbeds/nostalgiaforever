{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/deathbeds/nostalgiaforever/master?urlpath=lab/tree/readme.ipynb)[![Build Status](https://travis-ci.org/deathbeds/nostalgiaforever.svg?branch=master)](https://travis-ci.org/deathbeds/nostalgiaforever)[![PyPI version](https://badge.fury.io/py/nostalgiaforever.svg)](https://badge.fury.io/py/nostalgiaforever)![PyPI - Python Version](https://img.shields.io/pypi/pyversions/nostalgiaforever.svg)![PyPI - Format](https://img.shields.io/pypi/format/nostalgiaforever.svg)\n",
    "\n",
    "    pip install nostalgiaforever\n",
    "\n",
    "# A Notebook is a Hypothesis\n",
    "\n",
    "> ### If a notebook is a hypothesis then it can be tested.\n",
    "\n",
    "Modern scientists are transitioning to a generation where notebooks are common currency. Consider how testing and documentation are crucial aspect of reusable open source software. Those best practices evolved to support the communities developing that software. Generations of open source established idioms and style guides which enable software collaboration at global scale. Now, access to reusable software is blending with modern science, where both disciplines share similar global ambitions to solve increasing complex, multi-objective problems.\n",
    "\n",
    "Consequently, notebooks have evolved past being a medium for personal insight to become assets for community innovation. They represent extra-personal objects for scientists who have evaluated procedural \"units of thought\" as computational narratives. In a way, a notebook represents a modern form of hypothesis, and scientists must get comfortable sharing them rapidly. Unfortunately, new authors lack conventions for sharing notebooks as hypotheses within a scientific community. This talk presents tactics from literate programming to create readable, reusable, and reproducible notebooks. These notebook authoring practices promote improved documentation and unit testing.\n",
    "\n",
    "---\n",
    "\n",
    "[__@docfast__](https://twitter.com/DocFast) presenting behalf of [`deathbeds`](https://github.com/deathbeds/)\n",
    "\n",
    "\n",
    "* [`importnb`](https://github.com/deathbeds/importnb)\n",
    "* [`jupyterlab-fonts`](https://github.com/deathbeds/jupyterlab-fonts)\n",
    "* [`jyve`](https://deathbeds.github.io/jyve/lab/)\n",
    "\n",
    "[See __deathbeds__ present @ JupyterCon](https://conferences.oreilly.com/jupyter/jup-ny/public/schedule/detail/68439)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from nostalgiaforever import importing, testing, reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Technologies\n",
    "\n",
    "* [`importnb`](https://github.com/deathbeds/importnb)\n",
    "* [`doctest`](https://docs.python.org/3/library/doctest.html)\n",
    "* [`unittest`](https://docs.python.org/3/library/unittest.html)\n",
    "* [`pytest`](http://doc.pytest.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "* Notebooks can be used for testing and software.\n",
    "* Best practices for composing testable computational essays.\n",
    "* Existing testing frameworks can be used with notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order\n",
    "\n",
    "1. [`readme.ipynb`](readme.ipynb)\n",
    "1. [`importing.ipynb`](nostalgiaforever/importing.ipynb)\n",
    "2. [`testing.ipynb`](nostalgiaforever/testing.ipynb)\n",
    "3. [`reuse.ipynb`](nostalgiaforever/reuse.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before the talk\n",
    "\n",
    "* Restart your machine\n",
    "* Start the watcher\n",
    "\n",
    "        source activate p6 && cd ahypotehsis/nostalgiaforever && watchmedo tricks tricks.yml\n",
    "        \n",
    "            \n",
    "* Prepare the Fira Code fonts https://github.com/deathbeds/jupyterlab-fonts.\n",
    "* Hey art nerd! Turn the color on!\n",
    "* Cut the release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the docs.\n",
    "\n",
    "[Github Pages](https://deathbeds.github.io/nostalgiaforever/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watcher\n",
    "\n",
    "    source activate p6 && cd nostalgiaforever/ && watchmedo tricks tricks.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from nbconvert.exporters.markdown import MarkdownExporter\n",
    "    from nbconvert.preprocessors import Preprocessor\n",
    "    class ReplaceLinks(Preprocessor):\n",
    "        def preprocess_cell(self, cell, resources=None, index=0):\n",
    "            if cell['cell_type'] == 'markdown':\n",
    "                if isinstance(cell['source'], list): \n",
    "                    cell['source'] = ''.join(cell['source'])\n",
    "                cell['source'] = cell['source'].replace('.ipynb', '')\n",
    "            return cell, resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook readme.ipynb to markdown\n",
      "[NbConvertApp] Writing 5830 bytes to readme.md\n",
      "readme.ipynb\n",
      "nostalgiaforever/importing.ipynb\n",
      "nostalgiaforever/plugin.ipynb\n",
      "nostalgiaforever/reuse.ipynb\n",
      "nostalgiaforever/testing.ipynb\n",
      "nostalgiaforever/util.ipynb\n",
      "test/test_nostalgia.ipynb\n"
     ]
    }
   ],
   "source": [
    "    from pathlib import Path\n",
    "    if __name__ == '__main__':\n",
    "        from IPython import get_ipython\n",
    "        !jupyter nbconvert --to markdown readme.ipynb\n",
    "        for path in Path('.').rglob('*.ipynb'):\n",
    "            \n",
    "            if all(not part.startswith('.') for part in path.parts):\n",
    "                to = ('docs' / path)\n",
    "                print(path)\n",
    "                to.parent.mkdir(exist_ok=True)\n",
    "                MarkdownExporter(preprocessors=[ReplaceLinks()]).from_filename(path)[0]\n",
    "                to.with_suffix('.md').write_text(\n",
    "                    (\"---\\n\"*2 if len(path.parts) > 1 else \"\") + MarkdownExporter(preprocess=[ReplaceLinks()]).from_filename(path)[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "    if __name__ == '__main__':\n",
       "        try:\n",
       "            __import__('unittest').main('test', argv='--verbose'.split())\n",
       "        except SystemExit: ..."
      ],
      "text/plain": [
       "    if __name__ == '__main__':\n",
       "        try:\n",
       "            __import__('unittest').main('test', argv='--verbose'.split())\n",
       "        except SystemExit: ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "    if __name__ == '__main__':\n",
    "        try:\n",
    "            __import__('unittest').main('test', argv='--verbose'.split())\n",
    "        except SystemExit: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary [clear all output then \"Run All\" -- or it didn't happen]"
      ],
      "text/plain": [
       "# Summary [clear all output then \"Run All\" -- or it didn't happen]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary [clear all output then \"Run All\" -- or it didn't happen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if __name__ == '__main__':\n",
    "        !source activate p6 && ipython --profile pidgin -m nostalgiaforever.importing\n",
    "        !source activate p6 && ipython --profile pidgin -m nostalgiaforever.testing\n",
    "        !source activate p6 && ipython --profile pidgin -m nostalgiaforever.reuse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
